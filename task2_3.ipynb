{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Milestone I Natural Language Processing\n",
    "## Task 2&3\n",
    "#### Student Name: Mrwan Alhandi\n",
    "#### Student ID: s3969393\n",
    "\n",
    "Date: 9/10/23\n",
    "\n",
    "Version: 1.0\n",
    "\n",
    "Environment: Python 3 and Jupyter notebook\n",
    "\n",
    "Libraries used:\n",
    "* pandas\n",
    "* re\n",
    "* numpy\n",
    "* scikit-learn\n",
    "* json\n",
    "* Glove Embeddings were downloaded online\n",
    "\n",
    "## Introduction\n",
    "In this task, we will create different feature representations for job advertisement descriptions.The features to be generated include:\n",
    "\n",
    "1. Bag-of-Words (BoW) Model: Generate the Count vector representation for each job advertisement description.\n",
    "2. Both weighted (TF-IDF weighted) and unweighted vector representations using the Glove.\n",
    "\n",
    "To summarize, we will create three different types of feature representationsCount Vectors, TF-IDF weighted embeddings, and unweighted embeddings.\n",
    "\n",
    "Later in the Jupyter Notebook, different models are trained for each type of features and a cross validation is performed to assess the accuracy of each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Imports\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Generating Feature Representations for Job Advertisement Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocabulary(vocab_file):\n",
    "    \"\"\"This function loads the vocabulary from the disk\"\"\"\n",
    "    vocabulary = {}\n",
    "    with open(vocab_file, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            word, index = line.strip().split(':')\n",
    "            vocabulary[word] = int(index)\n",
    "    return vocabulary\n",
    "\n",
    "def create_count_vectorizer(vocabulary):\n",
    "    \"\"\"This function creates a CountVectorizer based on the loaded vocabulary\"\"\"\n",
    "    count_vectorizer = CountVectorizer(vocabulary=vocabulary)\n",
    "    return count_vectorizer\n",
    "\n",
    "def generate_count_vectors(df, count_vectorizer, column):\n",
    "    \"\"\"This function generates and saves the Count Vector representations\"\"\"\n",
    "    count_vectors = count_vectorizer.transform(df[column])\n",
    "    return count_vectors\n",
    "\n",
    "\n",
    "# Load all the three saved vocabularies\n",
    "vocabulary = load_vocabulary('vocab.txt')\n",
    "vocabulary_title = load_vocabulary('vocab_title.txt')\n",
    "vocabulary_concat_feature = load_vocabulary('vocab_concat_feature.txt')\n",
    "\n",
    "\n",
    "# Create CountVectorizers based on the loaded vocabularies\n",
    "count_vectorizer = create_count_vectorizer(vocabulary)\n",
    "count_vectorizer_title = create_count_vectorizer(vocabulary_title)\n",
    "count_vectorizer_concat_feature = create_count_vectorizer(vocabulary_concat_feature)\n",
    "\n",
    "\n",
    "# Read the data and convert the tokens back in a list form\n",
    "preprocessed_df = pd.read_excel(\"./combined_data.xlsx\")\n",
    "preprocessed_df[\"tokens\"] = preprocessed_df[\"tokens\"].apply(json.loads)\n",
    "preprocessed_df[\"title_tokens\"] = preprocessed_df[\"title_tokens\"].apply(json.loads)\n",
    "preprocessed_df[\"concat_feature_tokens\"] = preprocessed_df[\"concat_feature_tokens\"].apply(json.loads)\n",
    "\n",
    "\n",
    "# Generate and save the Count Vector representations\n",
    "count_vectors = generate_count_vectors(preprocessed_df, count_vectorizer, 'description')\n",
    "count_vectors_title = generate_count_vectors(preprocessed_df, count_vectorizer_title, 'title')\n",
    "count_vectors_concat_feature = generate_count_vectors(preprocessed_df, count_vectorizer_concat_feature, 'concat_feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(path):\n",
    "    \"\"\"This function loads GloVe word vectors into a dictionary\"\"\"\n",
    "    embeddings_index = {}\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = vector\n",
    "    return embeddings_index\n",
    "\n",
    "# Unweighted GloVe Embeddings\n",
    "def generate_unweighted_glove_embeddings(vocabulary, embedding_dim, embeddings_index):\n",
    "    \"\"\"Function for generating unweighted glove embeddings\"\"\"\n",
    "    embedding_matrix = np.zeros((len(vocabulary), embedding_dim))\n",
    "    \n",
    "    for word, index in vocabulary.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector\n",
    "            \n",
    "    return embedding_matrix\n",
    "\n",
    "# TF-IDF Weighted GloVe Embeddings\n",
    "def generate_weighted_glove_embeddings(text_data, vocabulary, embedding_dim, embeddings_index):\n",
    "    \"\"\"Function for generating weighted glove embeddings\"\"\"\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_vectorizer.fit(text_data)\n",
    "    \n",
    "    tfidf_vectors = tfidf_vectorizer.transform(text_data)\n",
    "    \n",
    "    weighted_glove_vectors = []\n",
    "    for i in range(len(text_data)):\n",
    "        words = text_data[i].split()\n",
    "        weighted_vector = np.zeros(embedding_dim)\n",
    "        for word in words:\n",
    "            if word in vocabulary and word in tfidf_vectorizer.vocabulary_:\n",
    "                tfidf_weight = tfidf_vectors[i, tfidf_vectorizer.vocabulary_[word]]\n",
    "                glove_embedding = embeddings_index.get(word)\n",
    "                if glove_embedding is not None:\n",
    "                    weighted_vector += tfidf_weight * glove_embedding\n",
    "        weighted_glove_vectors.append(weighted_vector)\n",
    "    \n",
    "    return weighted_glove_vectors\n",
    "\n",
    "\n",
    "# Load GloVe embeddings\n",
    "glove_path = \"./word_embeddings/glove.6B/glove.6B.100d.txt\"\n",
    "embeddings_index = load_glove_embeddings(glove_path)\n",
    "    \n",
    "# Load the data in a variable\n",
    "text_data = preprocessed_df[\"description\"]\n",
    "text_data_title = preprocessed_df[\"title\"]\n",
    "text_data_concat_feature = preprocessed_df[\"concat_feature\"]\n",
    "\n",
    "# Define embedding dimension\n",
    "embedding_dim = 100  # Can be adjusted according to GloVe embeddings\n",
    "\n",
    "# Generate unweighted GloVe embeddings for all three models\n",
    "unweighted_glove_embeddings = generate_unweighted_glove_embeddings(vocabulary, embedding_dim, embeddings_index)\n",
    "unweighted_glove_embeddings_title = generate_unweighted_glove_embeddings(vocabulary_title, embedding_dim, embeddings_index)\n",
    "unweighted_glove_embeddings_concat_feature = generate_unweighted_glove_embeddings(vocabulary_concat_feature, embedding_dim, embeddings_index)\n",
    "\n",
    "\n",
    "# Generate TF-IDF weighted GloVe embeddings for all three models\n",
    "weighted_glove_embeddings = generate_weighted_glove_embeddings(text_data, vocabulary, embedding_dim, embeddings_index)\n",
    "weighted_glove_embeddings_title = generate_weighted_glove_embeddings(text_data_title, vocabulary_title, embedding_dim, embeddings_index)\n",
    "weighted_glove_embeddings_concat_feature = generate_weighted_glove_embeddings(text_data_concat_feature, vocabulary_concat_feature, embedding_dim, embeddings_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_count_vector_representations(filename, vectors):\n",
    "    \"\"\"This function saves the Count Vector representations according to the format given\"\"\"\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        for webindex, count_vector in zip(preprocessed_df['webindex'], vectors):\n",
    "            non_zero_indices = count_vector.nonzero()[1]\n",
    "            counts = count_vector.data\n",
    "            representation = [f\"{index}:{count}\" for index, count in zip(non_zero_indices, counts)]\n",
    "            file.write(f\"#{webindex},{' '.join(representation)}\\n\")\n",
    "\n",
    "save_count_vector_representations('count_vectors.txt', count_vectors)\n",
    "save_count_vector_representations('count_vectors_title.txt', count_vectors_title)\n",
    "save_count_vector_representations('count_vectors_concat_feature.txt', count_vectors_concat_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the Main Model\n",
    "# Save the unweighted GloVe embeddings to a file\n",
    "np.save(\"unweighted_glove_embeddings.npy\", unweighted_glove_embeddings)\n",
    "\n",
    "# Save the weighted GloVe embeddings to a file\n",
    "np.save(\"weighted_glove_embeddings.npy\", weighted_glove_embeddings)\n",
    "\n",
    "\n",
    "# For title only\n",
    "# Save the unweighted GloVe embeddings to a file\n",
    "np.save(\"unweighted_glove_embeddings_title.npy\", unweighted_glove_embeddings)\n",
    "\n",
    "# Save the weighted GloVe embeddings to a file\n",
    "np.save(\"weighted_glove_embeddings_title.npy\", weighted_glove_embeddings)\n",
    "\n",
    "\n",
    "# For concatenated feature\n",
    "# Save the unweighted GloVe embeddings to a file\n",
    "np.save(\"unweighted_glove_embeddings_concat_feature.npy\", unweighted_glove_embeddings)\n",
    "\n",
    "# Save the weighted GloVe embeddings to a file\n",
    "np.save(\"weighted_glove_embeddings_concat_feature.npy\", weighted_glove_embeddings)\n",
    "\n",
    "\n",
    "\n",
    "# This code can be used to load the embeddings from the disk - Uncomment in case required\n",
    "# # Load unweighted GloVe embeddings\n",
    "# unweighted_glove_embeddings = np.load(\"unweighted_glove_embeddings.npy\")\n",
    "\n",
    "# # Load weighted GloVe embeddings\n",
    "# weighted_glove_embeddings = np.load(\"weighted_glove_embeddings.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Job Advertisement Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training - Description [Main Model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (weighted): 0.7435897435897436\n"
     ]
    }
   ],
   "source": [
    "# With weighted glove embeddings\n",
    "\n",
    "# Train Test Split - 80:20\n",
    "X_train, X_test, y_train, y_test = train_test_split(weighted_glove_embeddings, preprocessed_df[\"category\"], test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Logistic Regression classifier and fit it on the data\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# For prediction\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy (weighted):\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (unweighted): 0.8076923076923077\n"
     ]
    }
   ],
   "source": [
    "# For unweighted glove embeddings\n",
    "def get_aggregated_embeddings(column):\n",
    "    aggregated_embeddings = []\n",
    "\n",
    "    for tokens in (preprocessed_df[column]):\n",
    "        description_embedding = []\n",
    "        for token in tokens:\n",
    "            if token in vocabulary:\n",
    "                index = vocabulary[token]\n",
    "                embedding_vector = unweighted_glove_embeddings[index]\n",
    "                description_embedding.append(embedding_vector)\n",
    "\n",
    "        # Calculate the mean (average) embedding for the description\n",
    "        if description_embedding:\n",
    "            description_embedding = np.mean(description_embedding, axis=0)\n",
    "\n",
    "        else:\n",
    "            # If the description is empty or all tokens are out-of-vocabulary, use a zero vector\n",
    "            description_embedding = np.zeros(embedding_dim)\n",
    "\n",
    "        aggregated_embeddings.append(description_embedding)\n",
    "\n",
    "    # Convert the list of aggregated embeddings to a NumPy array\n",
    "    aggregated_embeddings = np.array(aggregated_embeddings)\n",
    "    \n",
    "    return aggregated_embeddings\n",
    "\n",
    "\n",
    "# With unweighted glove embeddings\n",
    "# Generate Aggregated Embeddings\n",
    "aggregated_embeddings = get_aggregated_embeddings(\"tokens\")\n",
    "\n",
    "\n",
    "# Train Test Split - 80:20\n",
    "X_train, X_test, y_train, y_test = train_test_split(aggregated_embeddings, preprocessed_df[\"category\"], test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Logistic Regression classifier and fit it on the data\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# For prediction\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy (unweighted):\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8846153846153846\n"
     ]
    }
   ],
   "source": [
    "# With Count Vectors\n",
    "\n",
    "# Train Test Split - 80:20\n",
    "X_train, X_test, y_train, y_test = train_test_split(count_vectors, preprocessed_df[\"category\"], test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the logistic regression model\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-Fold Cross Validation - Main Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results for Unweighted GloVe:\n",
      "Fold 1: 0.8333\n",
      "Fold 2: 0.8323\n",
      "Fold 3: 0.8903\n",
      "Fold 4: 0.7935\n",
      "Fold 5: 0.8839\n",
      "Mean Accuracy: 0.8467 (±0.0360)\n",
      "\n",
      "\n",
      "Cross-validation results for Weighted GloVe (TF-IDF):\n",
      "Fold 1: 0.7628\n",
      "Fold 2: 0.7613\n",
      "Fold 3: 0.8129\n",
      "Fold 4: 0.7161\n",
      "Fold 5: 0.8000\n",
      "Mean Accuracy: 0.7706 (±0.0340)\n",
      "\n",
      "\n",
      "Cross-validation results for Count Vectors:\n",
      "Fold 1: 0.8782\n",
      "Fold 2: 0.8258\n",
      "Fold 3: 0.8968\n",
      "Fold 4: 0.8516\n",
      "Fold 5: 0.9097\n",
      "Mean Accuracy: 0.8724 (±0.0304)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of folds for cross-validation\n",
    "n_folds = 5\n",
    "\n",
    "# Initialize the classifier (e.g., Logistic Regression)\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000)\n",
    "\n",
    "# Define the feature matrices and target labels\n",
    "X_unweighted_glove = aggregated_embeddings\n",
    "X_weighted_glove = weighted_glove_embeddings\n",
    "X_count_vectors = count_vectors \n",
    "y = preprocessed_df[\"category\"] \n",
    "\n",
    "# Initialize cross-validation splitter\n",
    "cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation for each feature representation\n",
    "for X, representation_name in [(X_unweighted_glove, \"Unweighted GloVe\"),\n",
    "                               (X_weighted_glove, \"Weighted GloVe (TF-IDF)\"),\n",
    "                               (X_count_vectors, \"Count Vectors\")]:\n",
    "    print(f\"Cross-validation results for {representation_name}:\")\n",
    "    \n",
    "    # Perform cross-validation and calculate accuracy scores\n",
    "    scores = cross_val_score(clf, X, y, cv=cv, scoring='accuracy')\n",
    "    \n",
    "    # Print accuracy scores for each fold\n",
    "    for fold, score in enumerate(scores, start=1):\n",
    "        print(f\"Fold {fold}: {score:.4f}\")\n",
    "    \n",
    "    # Calculate and print the mean accuracy and standard deviation\n",
    "    mean_accuracy = scores.mean()\n",
    "    std_accuracy = scores.std()\n",
    "    print(f\"Mean Accuracy: {mean_accuracy:.4f} (±{std_accuracy:.4f})\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the 5-Fold Cross valiadation above, encodings from the count vectors performed the best with an accuracy of 87.2%, followed by Unweighted Glove with an accuracy of 84.67%. This addresses the first question which asks about the model comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-Fold Cross Validation - Title Only Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results for Unweighted GloVe:\n",
      "Fold 1: 0.5128\n",
      "Fold 2: 0.4839\n",
      "Fold 3: 0.6000\n",
      "Fold 4: 0.5548\n",
      "Fold 5: 0.5742\n",
      "Mean Accuracy: 0.5451 (±0.0418)\n",
      "\n",
      "\n",
      "Cross-validation results for Weighted GloVe (TF-IDF):\n",
      "Fold 1: 0.2885\n",
      "Fold 2: 0.3032\n",
      "Fold 3: 0.3097\n",
      "Fold 4: 0.3161\n",
      "Fold 5: 0.3097\n",
      "Mean Accuracy: 0.3054 (±0.0094)\n",
      "\n",
      "\n",
      "Cross-validation results for Count Vectors:\n",
      "Fold 1: 0.6218\n",
      "Fold 2: 0.5935\n",
      "Fold 3: 0.6323\n",
      "Fold 4: 0.5677\n",
      "Fold 5: 0.6452\n",
      "Mean Accuracy: 0.6121 (±0.0279)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Modelling using title of the job advertisement\n",
    "# Number of folds for cross-validation\n",
    "n_folds = 5\n",
    "\n",
    "# Initialize the classifier (e.g., Logistic Regression)\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000)\n",
    "\n",
    "# Define the feature matrices and target labels\n",
    "X_unweighted_glove = get_aggregated_embeddings(\"title_tokens\")\n",
    "X_weighted_glove = weighted_glove_embeddings_title\n",
    "X_count_vectors = count_vectors_title\n",
    "y = preprocessed_df[\"category\"] \n",
    "\n",
    "# Initialize cross-validation splitter\n",
    "cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation for each feature representation\n",
    "for X, representation_name in [(X_unweighted_glove, \"Unweighted GloVe\"),\n",
    "                               (X_weighted_glove, \"Weighted GloVe (TF-IDF)\"),\n",
    "                               (X_count_vectors, \"Count Vectors\")]:\n",
    "    print(f\"Cross-validation results for {representation_name}:\")\n",
    "    \n",
    "    # Perform cross-validation and calculate accuracy scores\n",
    "    scores = cross_val_score(clf, X, y, cv=cv, scoring='accuracy')\n",
    "    \n",
    "    # Print accuracy scores for each fold\n",
    "    for fold, score in enumerate(scores, start=1):\n",
    "        print(f\"Fold {fold}: {score:.4f}\")\n",
    "    \n",
    "    # Calculate and print the mean accuracy and standard deviation\n",
    "    mean_accuracy = scores.mean()\n",
    "    std_accuracy = scores.std()\n",
    "    print(f\"Mean Accuracy: {mean_accuracy:.4f} (±{std_accuracy:.4f})\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-Fold Cross Validation - Combined Data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results for Unweighted GloVe:\n",
      "Fold 1: 0.8269\n",
      "Fold 2: 0.8516\n",
      "Fold 3: 0.8968\n",
      "Fold 4: 0.8194\n",
      "Fold 5: 0.8903\n",
      "Mean Accuracy: 0.8570 (±0.0318)\n",
      "\n",
      "\n",
      "Cross-validation results for Weighted GloVe (TF-IDF):\n",
      "Fold 1: 0.7564\n",
      "Fold 2: 0.7677\n",
      "Fold 3: 0.8000\n",
      "Fold 4: 0.7161\n",
      "Fold 5: 0.7935\n",
      "Mean Accuracy: 0.7668 (±0.0300)\n",
      "\n",
      "\n",
      "Cross-validation results for Count Vectors:\n",
      "Fold 1: 0.8846\n",
      "Fold 2: 0.8194\n",
      "Fold 3: 0.9097\n",
      "Fold 4: 0.8452\n",
      "Fold 5: 0.9161\n",
      "Mean Accuracy: 0.8750 (±0.0373)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Modelling Using Concatenated Data\n",
    "# Number of folds for cross-validation\n",
    "n_folds = 5\n",
    "\n",
    "# Initialize the classifier (e.g., Logistic Regression)\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000)\n",
    "\n",
    "# Define the feature matrices and target labels\n",
    "X_unweighted_glove = get_aggregated_embeddings(\"concat_feature_tokens\")\n",
    "X_weighted_glove = weighted_glove_embeddings_concat_feature\n",
    "X_count_vectors = count_vectors_concat_feature\n",
    "y = preprocessed_df[\"category\"] \n",
    "\n",
    "# Initialize cross-validation splitter\n",
    "cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation for each feature representation\n",
    "for X, representation_name in [(X_unweighted_glove, \"Unweighted GloVe\"),\n",
    "                               (X_weighted_glove, \"Weighted GloVe (TF-IDF)\"),\n",
    "                               (X_count_vectors, \"Count Vectors\")]:\n",
    "    print(f\"Cross-validation results for {representation_name}:\")\n",
    "    \n",
    "    # Perform cross-validation and calculate accuracy scores\n",
    "    scores = cross_val_score(clf, X, y, cv=cv, scoring='accuracy')\n",
    "    \n",
    "    # Print accuracy scores for each fold\n",
    "    for fold, score in enumerate(scores, start=1):\n",
    "        print(f\"Fold {fold}: {score:.4f}\")\n",
    "    \n",
    "    # Calculate and print the mean accuracy and standard deviation\n",
    "    mean_accuracy = scores.mean()\n",
    "    std_accuracy = scores.std()\n",
    "    print(f\"Mean Accuracy: {mean_accuracy:.4f} (±{std_accuracy:.4f})\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the model training, if we used only the title the accuracy of the model drops significantly. \n",
    "If title is used along with the description column, then accuracy roughly remains the same which indicates that there is small prediction power in the title column. As per question 2, in our case, even though we added more data to the description, our accuracy was not improved. This means that if data quality is not good, it does not help the model improve its predictions. Infact, this can hurt the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "The Jupyter Notebook explored three different techniques to build word vectors and later showed the results of model training in each of those cases. The 5-fold cross validation was employed in assessing the results of the model. Overall, count vectorizer proved to be a very powerful technique for the data given."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
