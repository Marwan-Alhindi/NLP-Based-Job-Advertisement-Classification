{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Milestone I Natural Language Processing\n",
    "## Task 1. Basic Text Pre-processing\n",
    "#### Student Name: Mrwan Alhandi\n",
    "#### Student ID: s3969393\n",
    "\n",
    "Date: 9/10/23\n",
    "\n",
    "Version: 1.0\n",
    "\n",
    "Environment: Python 3 and Jupyter notebook\n",
    "\n",
    "Libraries used:\n",
    "* pandas\n",
    "* re\n",
    "* numpy\n",
    "* json\n",
    "* collections\n",
    "* glob\n",
    "\n",
    "## Introduction\n",
    "In this task, we will perform text pre-processing on a given dataset, focusing on the description of job advertisements. The following steps are executed:\n",
    "\n",
    "1. Extraction of information from each job advertisement.\n",
    "2. Tokenization using specific regular expression.\n",
    "3. Conversion of all words to lowercase.\n",
    "4. Removal of words with a length of less than 2.\n",
    "5. Elimination of stopwords using the provided stop words list (stopwords_en.txt).\n",
    "6. Removal of words that appear only once in the document collection based on term frequency.\n",
    "7. Removal of the top 50 most frequent words based on document frequency.\n",
    "8. Saving of preprocessed job advertisement text and information in the given format.\n",
    "9. Building a vocabulary of cleaned job advertisement descriptions and saving it in a txt file.\n",
    "\n",
    "These pre-processing steps prepare the data for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Imports\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Examining and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files_in_folder(folder_path):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function reads the files from the paths provided\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            lines = file.readlines()\n",
    "            entry = {\"title\": None, \"webindex\": None, \"company\": None, \"description\": None}\n",
    "            for line in lines:\n",
    "                key, value = map(str.strip, line.split(\":\", 1))\n",
    "                entry[key.lower()] = value\n",
    "            data.append(entry)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_paths = glob.glob(\"./data/*\")\n",
    "\n",
    "combined_data = []\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "    category = os.path.split(folder_path)[1]\n",
    "    folder_data = read_files_in_folder(folder_path)\n",
    "    category_data = pd.DataFrame(folder_data)\n",
    "    category_data[\"category\"] = category\n",
    "    combined_data.append(category_data)\n",
    "    \n",
    "combined_data = pd.concat(combined_data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Engineering           231\n",
       "Healthcare_Nursing    198\n",
       "Accounting_Finance    191\n",
       "Sales                 156\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of files for each of the different categories\n",
    "combined_data[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(776, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>webindex</th>\n",
       "      <th>company</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FP&amp;A  Blue Chip</td>\n",
       "      <td>68802053</td>\n",
       "      <td>Hays Senior Finance</td>\n",
       "      <td>A market leading retail business is going thro...</td>\n",
       "      <td>Accounting_Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Part time Management Accountant</td>\n",
       "      <td>70757636</td>\n",
       "      <td>FS2 UK Ltd</td>\n",
       "      <td>You will be responsible for the efficient runn...</td>\n",
       "      <td>Accounting_Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IFA  EMPLOYED</td>\n",
       "      <td>71356489</td>\n",
       "      <td>Clark James Ltd</td>\n",
       "      <td>Role The purpose of the role is to provide adv...</td>\n",
       "      <td>Accounting_Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Finance Manager</td>\n",
       "      <td>69073629</td>\n",
       "      <td>Accountancy Action Ltd</td>\n",
       "      <td>Excellent opportunity to join our client, an e...</td>\n",
       "      <td>Accounting_Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Management Accountant</td>\n",
       "      <td>70656648</td>\n",
       "      <td>Alexander Lloyd</td>\n",
       "      <td>Our client offers a interesting opportunity fo...</td>\n",
       "      <td>Accounting_Finance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title  webindex                 company  \\\n",
       "0                  FP&A  Blue Chip  68802053     Hays Senior Finance   \n",
       "1  Part time Management Accountant  70757636              FS2 UK Ltd   \n",
       "2                    IFA  EMPLOYED  71356489         Clark James Ltd   \n",
       "3                  Finance Manager  69073629  Accountancy Action Ltd   \n",
       "4            Management Accountant  70656648         Alexander Lloyd   \n",
       "\n",
       "                                         description            category  \n",
       "0  A market leading retail business is going thro...  Accounting_Finance  \n",
       "1  You will be responsible for the efficient runn...  Accounting_Finance  \n",
       "2  Role The purpose of the role is to provide adv...  Accounting_Finance  \n",
       "3  Excellent opportunity to join our client, an e...  Accounting_Finance  \n",
       "4  Our client offers a interesting opportunity fo...  Accounting_Finance  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(df, column):\n",
    "    \"\"\"\n",
    "    This function preprocesses the data given the column on which\n",
    "    preprocessing is to be applied\n",
    "    \"\"\"\n",
    "    # Define the tokenization function\n",
    "    def tokenize(column):\n",
    "        # Use the regular expression pattern for tokenization\n",
    "        pattern = r\"[a-zA-Z]+(?:[-'][a-zA-Z]+)?\"\n",
    "        tokens = re.findall(pattern, column.lower())  # Convert to lowercase\n",
    "        return tokens\n",
    "\n",
    "    # Apply the tokenization function to the input column\n",
    "    df['tokens'] = df[column].apply(tokenize)\n",
    "\n",
    "    # Calculate document frequency (DF) for each word in the document collection\n",
    "    document_frequency = Counter()\n",
    "    for tokens in df['tokens']:\n",
    "        document_frequency.update(set(tokens))  # Using set to count each word only once per document\n",
    "\n",
    "    # Identify words that appear only once (DF == 1)\n",
    "    rare_words = [word for word, df in document_frequency.items() if df == 1]\n",
    "\n",
    "    # Identify the top 50 most frequent words in terms of term frequency\n",
    "    term_frequency = Counter()\n",
    "    for tokens in df['tokens']:\n",
    "        term_frequency.update(tokens)\n",
    "\n",
    "    top_50_words = [word for word, tf in term_frequency.most_common(50)]\n",
    "\n",
    "    # Define a function to remove stopwords, words less than length 3, rare words, and top 50 frequent words\n",
    "    def remove_words(tokens):\n",
    "        # Read stop words from stopwords_en.txt\n",
    "        with open(\"stopwords_en.txt\", \"r\") as stopword_file:\n",
    "            stop_words = stopword_file.read().splitlines()\n",
    "        \n",
    "        # Combine the lists of stop words, rare words, and top 50 frequent words\n",
    "        words_to_remove = set(stop_words + rare_words + top_50_words)\n",
    "        \n",
    "        return [token for token in tokens if token not in words_to_remove and len(token) >= 3]\n",
    "\n",
    "    # Apply the remove_words function to the 'tokens' column\n",
    "    df['tokens'] = df['tokens'].apply(remove_words)\n",
    "\n",
    "    return df\n",
    "\n",
    "    \n",
    "# Preprocessing is done for all the three models - [Title Only, Description, and Both]\n",
    "\n",
    "# Preprocessing for Title Only Model\n",
    "combined_data = preprocess_text(combined_data, \"title\")\n",
    "combined_data.rename(columns={'tokens': 'title_tokens'}, inplace=True)\n",
    "\n",
    "# Preprocessing for Concat Model - Uses both Title and Description\n",
    "combined_data[\"concat_feature\"] = combined_data[\"title\"] + \" \"+ combined_data[\"description\"]\n",
    "combined_data = preprocess_text(combined_data, \"concat_feature\")\n",
    "combined_data.rename(columns={'tokens': 'concat_feature_tokens'}, inplace=True)\n",
    "\n",
    "# Preprocessing for Main Model - [Description]\n",
    "combined_data = preprocess_text(combined_data, \"description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>webindex</th>\n",
       "      <th>company</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "      <th>title_tokens</th>\n",
       "      <th>concat_feature</th>\n",
       "      <th>concat_feature_tokens</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FP&amp;A  Blue Chip</td>\n",
       "      <td>68802053</td>\n",
       "      <td>Hays Senior Finance</td>\n",
       "      <td>A market leading retail business is going thro...</td>\n",
       "      <td>Accounting_Finance</td>\n",
       "      <td>[]</td>\n",
       "      <td>FP&amp;A  Blue Chip A market leading retail busine...</td>\n",
       "      <td>[blue, chip, market, leading, retail, rapid, g...</td>\n",
       "      <td>[market, leading, retail, rapid, growth, due, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Part time Management Accountant</td>\n",
       "      <td>70757636</td>\n",
       "      <td>FS2 UK Ltd</td>\n",
       "      <td>You will be responsible for the efficient runn...</td>\n",
       "      <td>Accounting_Finance</td>\n",
       "      <td>[part, management]</td>\n",
       "      <td>Part time Management Accountant You will be re...</td>\n",
       "      <td>[part, time, accountant, responsible, efficien...</td>\n",
       "      <td>[responsible, efficient, running, accounting, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IFA  EMPLOYED</td>\n",
       "      <td>71356489</td>\n",
       "      <td>Clark James Ltd</td>\n",
       "      <td>Role The purpose of the role is to provide adv...</td>\n",
       "      <td>Accounting_Finance</td>\n",
       "      <td>[ifa]</td>\n",
       "      <td>IFA  EMPLOYED Role The purpose of the role is ...</td>\n",
       "      <td>[ifa, employed, purpose, provide, advice, tele...</td>\n",
       "      <td>[purpose, provide, advice, telephone, leads, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Finance Manager</td>\n",
       "      <td>69073629</td>\n",
       "      <td>Accountancy Action Ltd</td>\n",
       "      <td>Excellent opportunity to join our client, an e...</td>\n",
       "      <td>Accounting_Finance</td>\n",
       "      <td>[]</td>\n",
       "      <td>Finance Manager Excellent opportunity to join ...</td>\n",
       "      <td>[finance, opportunity, join, expanding, based,...</td>\n",
       "      <td>[opportunity, join, expanding, based, recruit,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Management Accountant</td>\n",
       "      <td>70656648</td>\n",
       "      <td>Alexander Lloyd</td>\n",
       "      <td>Our client offers a interesting opportunity fo...</td>\n",
       "      <td>Accounting_Finance</td>\n",
       "      <td>[management]</td>\n",
       "      <td>Management Accountant Our client offers a inte...</td>\n",
       "      <td>[accountant, offers, interesting, opportunity,...</td>\n",
       "      <td>[offers, interesting, opportunity, part, quali...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title  webindex                 company  \\\n",
       "0                  FP&A  Blue Chip  68802053     Hays Senior Finance   \n",
       "1  Part time Management Accountant  70757636              FS2 UK Ltd   \n",
       "2                    IFA  EMPLOYED  71356489         Clark James Ltd   \n",
       "3                  Finance Manager  69073629  Accountancy Action Ltd   \n",
       "4            Management Accountant  70656648         Alexander Lloyd   \n",
       "\n",
       "                                         description            category  \\\n",
       "0  A market leading retail business is going thro...  Accounting_Finance   \n",
       "1  You will be responsible for the efficient runn...  Accounting_Finance   \n",
       "2  Role The purpose of the role is to provide adv...  Accounting_Finance   \n",
       "3  Excellent opportunity to join our client, an e...  Accounting_Finance   \n",
       "4  Our client offers a interesting opportunity fo...  Accounting_Finance   \n",
       "\n",
       "         title_tokens                                     concat_feature  \\\n",
       "0                  []  FP&A  Blue Chip A market leading retail busine...   \n",
       "1  [part, management]  Part time Management Accountant You will be re...   \n",
       "2               [ifa]  IFA  EMPLOYED Role The purpose of the role is ...   \n",
       "3                  []  Finance Manager Excellent opportunity to join ...   \n",
       "4        [management]  Management Accountant Our client offers a inte...   \n",
       "\n",
       "                               concat_feature_tokens  \\\n",
       "0  [blue, chip, market, leading, retail, rapid, g...   \n",
       "1  [part, time, accountant, responsible, efficien...   \n",
       "2  [ifa, employed, purpose, provide, advice, tele...   \n",
       "3  [finance, opportunity, join, expanding, based,...   \n",
       "4  [accountant, offers, interesting, opportunity,...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [market, leading, retail, rapid, growth, due, ...  \n",
       "1  [responsible, efficient, running, accounting, ...  \n",
       "2  [purpose, provide, advice, telephone, leads, s...  \n",
       "3  [opportunity, join, expanding, based, recruit,...  \n",
       "4  [offers, interesting, opportunity, part, quali...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving required outputs\n",
    "Save the vocabulary, bigrams and job advertisment txt as per spectification.\n",
    "- vocab.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the vocabulary\n",
    "def build_vocabulary(df, output_file, column):\n",
    "    \"\"\"\n",
    "    This function is used to build the vocabulary for the column type provided.\n",
    "    \"\"\"\n",
    "    # Concatenate all cleaned descriptions into a single string\n",
    "    cleaned_text = \" \".join(\" \".join(tokens) for tokens in df[column])\n",
    "\n",
    "    # Tokenize the concatenated text to get the vocabulary\n",
    "    vocabulary = sorted(set(cleaned_text.split()))\n",
    "    \n",
    "    # Save the vocabulary to a text file with word:integer_index format\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        for i, word in enumerate(vocabulary):\n",
    "            file.write(f\"{word}:{i}\\n\")\n",
    "\n",
    "\n",
    "# Build and save the vocabulary to a text file - [General Model]\n",
    "build_vocabulary(combined_data, 'vocab.txt', 'tokens')\n",
    "\n",
    "# Build and save vocab for title_tokens - [Title Only Model]\n",
    "build_vocabulary(combined_data, 'vocab_title.txt', 'title_tokens')\n",
    "\n",
    "# Build and save vocab for concat_feature_tokens - [Combined Model]\n",
    "build_vocabulary(combined_data, 'vocab_concat_feature.txt', 'concat_feature_tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the lists as JSON objects for easier loading in the other Jupyter Notebook\n",
    "combined_data[\"tokens\"] = combined_data[\"tokens\"].apply(json.dumps)\n",
    "combined_data[\"title_tokens\"] = combined_data[\"title_tokens\"].apply(json.dumps)\n",
    "combined_data[\"concat_feature_tokens\"] = combined_data[\"concat_feature_tokens\"].apply(json.dumps)\n",
    "\n",
    "# Saving the data for the later use\n",
    "combined_data.to_excel(\"./combined_data.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "This Jupyter Notebook generates four different files.\n",
    "Three vocabulary files for three different types of modelling techniques and a combined data file which will be used in all the models in the task2 Jupyter Notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
